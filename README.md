# MINIMINIMOON - Sistema Can√≥nico de Evaluaci√≥n de PDM

**Versi√≥n:** 2.0.0  
**Fecha:** 6 de octubre de 2025  
**Estado:** ‚úÖ Verificado - Todos los flujos cr√≠ticos operativos

---

## üìë Tabla de Contenidos

1. [üéØ Descripci√≥n](#-descripci√≥n)
2. [üì¶ Instalaci√≥n Completa (Paso a Paso)](#-instalaci√≥n-completa-paso-a-paso)
   - [Requisitos Previos](#requisitos-previos)
   - [Instalaci√≥n Manual (11 Pasos)](#paso-1-verificar-python-310)
   - [Instalaci√≥n Automatizada](#instalaci√≥n-automatizada-script)
3. [üöÄ Gu√≠a de Implementaci√≥n (Workflow Completo)](#-gu√≠a-de-implementaci√≥n-workflow-completo)
   - [Paso 1: Congelar Configuraci√≥n (Gate #1)](#paso-1-congelar-configuraci√≥n-gate-1---obligatorio)
   - [Paso 2: Verificar Estado](#paso-2-verificar-estado-del-sistema-pre-ejecuci√≥n)
   - [Paso 3: Primera Evaluaci√≥n](#paso-3-ejecutar-primera-evaluaci√≥n-de-pdm)
   - [Paso 4: Inspeccionar Resultados](#paso-4-inspeccionar-resultados)
   - [Paso 5: Verificar Reproducibilidad](#paso-5-verificar-reproducibilidad-gate-3---cr√≠tico)
   - [Paso 6: Validar R√∫brica](#paso-6-validar-alineaci√≥n-de-r√∫brica-gate-5)
   - [Paso 7: Matriz de Trazabilidad](#paso-7-generar-matriz-de-trazabilidad)
   - [Paso 8: Verificaci√≥n Completa](#paso-8-verificaci√≥n-post-ejecuci√≥n-completa)
4. [üîß Uso Program√°tico (API Python)](#-uso-program√°tico-api-python)
5. [üÜò Troubleshooting](#-troubleshooting-soluci√≥n-de-problemas)
6. [üèóÔ∏è Arquitectura del Sistema](#Ô∏è-arquitectura-del-sistema)
7. [üõ°Ô∏è Gates de Aceptaci√≥n](#Ô∏è-gates-de-aceptaci√≥n-verificaci√≥n-autom√°tica)
8. [üìÅ Archivos Fundamentales](#-archivos-fundamentales-del-sistema)
9. [üìä Salidas del Sistema](#-salidas-del-sistema)
10. [üìä Visual Architecture Diagrams](#-visual-architecture-diagrams)
11. [üß™ Testing y Verificaci√≥n](#-testing-y-verificaci√≥n)
12. [ü§ù Contribuci√≥n](#-contribuci√≥n)
13. [üìö Documentaci√≥n Adicional](#-documentaci√≥n-adicional)
14. [‚ö° Quick Reference (Comandos Comunes)](#-quick-reference-comandos-comunes)

---

## üéØ Descripci√≥n

Sistema de evaluaci√≥n determinista y reproducible de Planes de Desarrollo Municipal (PDM) basado en:
- **300 preguntas** estructuradas en 10 puntos tem√°ticos √ó 30 preguntas
- **Flujo can√≥nico √∫nico** con 72 flujos cr√≠ticos verificados
- **6 gates de aceptaci√≥n** obligatorios para garantizar calidad
- **Evidence Registry √∫nico** (single source of truth)
- **Trazabilidad completa** desde evidencia hasta respuesta final

---

## üèóÔ∏è Arquitectura del Sistema

> **üìä Visual Architecture**: See [complete visual documentation](#-visual-architecture-diagrams) with 7 advanced diagrams depicting system flow, validation gates, and deployment infrastructure.

### Orquestador Principal (Entry Point √önico)

```python
from miniminimoon_orchestrator import CanonicalDeterministicOrchestrator

orchestrator = CanonicalDeterministicOrchestrator(
    config_dir=".",
    enable_validation=True,
    flow_doc_path="tools/flow_doc.json"
)

results = orchestrator.process_plan_deterministic(plan_path)
```

### üîÑ Pipeline Can√≥nico (15 Etapas Secuenciales)

#### **Fase 1: Procesamiento (Etapas 1-11)**

1. **Sanitizaci√≥n** (`plan_sanitizer`)
   - Input: `{raw_text: str}`
   - Output: `{sanitized_text: str}`
   - Normalizaci√≥n determinista del texto

2. **Procesamiento de Plan** (`plan_processor`)
   - Input: `{sanitized_text: str}`
   - Output: `{doc_struct: dict}`
   - Estructura estable para trazabilidad

3. **Segmentaci√≥n** (`document_segmenter`)
   - Input: `{doc_struct: dict}`
   - Output: `{segments: list[dict]}`
   - Granularidad por pregunta con IDs deterministas

4. **Embeddings** (`embedding_model`)
   - Input: `{segments: list}`
   - Output: `{embeddings: list}`
   - B√∫squeda sem√°ntica reproducible (seed fija)

5. **Detecci√≥n de Responsabilidades** (`responsibility_detector`)
   - Input: `{segments: list}`
   - Output: `{responsibilities: list[dict]}`
   - Mapea responsables a preguntas DE-1/DE-3

6. **Detecci√≥n de Contradicciones** (`contradiction_detector`)
   - Input: `{segments: list}`
   - Output: `{contradictions: list[dict]}`
   - Consistencia y penalizaciones de rubro

7. **Detecci√≥n Monetaria** (`monetary_detector`)
   - Input: `{segments: list}`
   - Output: `{monetary: list[dict]}`
   - Costos/metas financieras

8. **Scoring de Factibilidad** (`feasibility_scorer`)
   - Input: `{segments: list}`
   - Output: `{feasibility: dict}`
   - Presencia de l√≠neas base/objetivos/metas

9. **Patrones Causales** (`causal_pattern_detector`)
   - Input: `{segments: list}`
   - Output: `{causal_patterns: dict}`
   - Soporte causal para respuestas explicativas

10. **Teor√≠a del Cambio** (`teoria_cambio`)
    - Input: `{segments: list}`
    - Output: `{toc_graph: dict, industrial_validation: dict}`
    - Coherencia medios-fines + reporte industrial completo

11. **Validaci√≥n DAG** (`dag_validation`)
    - Input: `{toc_graph: dict}`
    - Output: `{dag_diagnostics: dict}`
    - Validez estructural (DAG) verificable

#### **Fase 2: Construcci√≥n de Evidencia (Etapa 12)**

1. **Evidence Registry** (Fan-in N:1)
    - Input: Outputs de etapas 5-11
    - Output: `{evidence_hash: str, evidence_store: dict}`
    - **√önico origen de verdad** para evaluadores
    - Provenance completo + hash determinista

#### **Fase 3: Evaluaci√≥n (Etapas 13-14)**

1. **Evaluaci√≥n Dec√°logo** (`Decatalogo_principal`)
    - Input: `{evidence_store}`
    - Output: `{decalogo_eval: dict}`
    - Evaluaci√≥n data-driven por dimensi√≥n/pregunta

2. **Evaluaci√≥n Cuestionario** (`questionnaire_engine`)
    - Input: `{evidence_store}`
    - Output: `{questionnaire_eval: dict}`
    - 300 preguntas sobre la misma evidencia

#### **Fase 4: Ensamblaje Final (Etapa 15)**

1. **Answer Assembler** (`answer_assembler`)
    - Input: `{evidence_store, rubric, decalogo_eval, questionnaire_eval}`
    - Output: `{answers_report: dict}`
    - Respuestas con evidence_ids, confidence, score y rationale

---

## üõ°Ô∏è Gates de Aceptaci√≥n (Verificaci√≥n Autom√°tica)

### Gate #1: Configuraci√≥n Inmutable ‚úÖ
```bash
python miniminimoon_cli.py freeze
```
- Verifica: `verify_frozen_config() == True`
- Crea snapshot SHA-256 de configuraciones cr√≠ticas
- **Bloqueo:** Pipeline no ejecuta sin snapshot v√°lido

### Gate #2: Validaci√≥n de Flujo ‚úÖ
- Compara: `flow_runtime.json` vs `tools/flow_doc.json`
- Verifica: Orden can√≥nico + contratos I/O
- **Bloqueo:** Falla si orden o contratos divergen

### Gate #3: Hash de Evidencia Determinista ‚úÖ
- Verifica: `evidence_hash` estable con mismo input
- **Bloqueo:** Triple-run debe producir mismo hash

### Gate #4: Cobertura Completa ‚úÖ
- Verifica: `answers_report.summary.total_questions ‚â• 300`
- **Bloqueo:** Falla si no se responden las 300 preguntas

### Gate #5: Alineaci√≥n de R√∫brica ‚úÖ
```bash
python miniminimoon_cli.py rubric-check
```
- Verifica: 1:1 preguntas ‚Üî pesos (sin missing/extra)
- **Bloqueo:** Exit code 3 si hay desalineaci√≥n

### Gate #6: No Deprecated Orchestrator ‚úÖ
- Verifica: `decalogo_pipeline_orchestrator` NO usado
- **Bloqueo:** RuntimeError al importar m√≥dulo deprecado

---

## üìÅ Archivos Fundamentales del Sistema

### 1. Configuraci√≥n (3 archivos obligatorios)

```
decalogo_industrial.json          # √öNICO DEC√ÅLOGO (cuestionario 300 preguntas)
dnp-standards.latest.clean.json   # Est√°ndares DNP
RUBRIC_SCORING.json                # Sistema de scoring y pesos
```

### 2. C√≥digo Core

```
miniminimoon_orchestrator.py      # Orquestador can√≥nico (√öNICO punto de entrada)
unified_evaluation_pipeline.py    # Fachada unificada con pre/post validation
answer_assembler.py                # Ensamblador de respuestas finales
evidence_registry.py               # Registro √∫nico de evidencia
system_validators.py               # Validadores pre/post ejecuci√≥n
```

### 3. Componentes del Pipeline (11 m√≥dulos)

```
plan_sanitizer.py                  # Etapa 1: Sanitizaci√≥n
plan_processor.py                  # Etapa 2: Procesamiento
document_segmenter.py              # Etapa 3: Segmentaci√≥n
embedding_model.py                 # Etapa 4: Embeddings
responsibility_detector.py         # Etapa 5: Responsabilidades
contradiction_detector.py          # Etapa 6: Contradicciones
monetary_detector.py               # Etapa 7: Detecci√≥n monetaria
feasibility_scorer.py              # Etapa 8: Factibilidad
causal_pattern_detector.py        # Etapa 9: Patrones causales
teoria_cambio.py                   # Etapa 10: Teor√≠a del cambio
dag_validation.py                  # Etapa 11: Validaci√≥n DAG
```

### 4. Evaluadores

```
Decatalogo_principal.py            # Evaluador por dimensiones
questionnaire_engine.py            # Motor de 300 preguntas
```

### 5. Herramientas de Verificaci√≥n

```
miniminimoon_cli.py                # CLI: freeze, evaluate, verify, rubric-check, trace-matrix
system_validators.py               # Validadores pre/post ejecuci√≥n
test_validation_end_to_end.py      # Verificaci√≥n end-to-end
tools/flow_doc.json                # Orden can√≥nico documentado
determinism_guard.py               # Fijaci√≥n de seeds deterministas
```

### 6. Documentaci√≥n

```
DEPRECATIONS.md                    # M√≥dulos deprecados y migraci√≥n
FLUJOS_CRITICOS_GARANTIZADOS.md   # 72 flujos cr√≠ticos detallados
ARCHITECTURE.md                    # Arquitectura del sistema
DEPLOYMENT_INFRASTRUCTURE.md       # Infraestructura de deployment
```

---

## üì¶ Instalaci√≥n Completa (Paso a Paso)

> **üöÄ NEW: Automated Installation**
> 
> We now provide an automated installation script with dependency verification:
> ```bash
> bash scripts/install_verified.sh
> ```
> This script handles Python version checking, dependency installation, and verification automatically.
>
> For manual installation or troubleshooting, see the detailed steps below.

### Quick Start (Automated Installation)

The fastest way to get started is using our verified installation script:

```bash
# 1. Clone the repository
git clone https://github.com/ANITALAVALATINACONPRISA/SIN_CARRETA.git
cd SIN_CARRETA

# 2. Run automated installation
bash scripts/install_verified.sh
```

The script will:
- ‚úÖ Verify Python version (3.10-3.12)
- ‚úÖ Prompt for CPU or GPU PyTorch installation
- ‚úÖ Install all core dependencies
- ‚úÖ Download spaCy language models
- ‚úÖ Run conflict detection
- ‚úÖ Generate compatibility certificate
- ‚úÖ Verify critical imports

### System Requirements

**Python Version:**
- **Python 3.10, 3.11, or 3.12** (REQUIRED)
- Other versions are NOT supported due to:
  - NumPy >=1.21.0 compatibility (first version with Python 3.10 wheels)
  - Modern type hints and pattern matching features
  - Tested dependency combinations

**Operating System:**
- Linux (Ubuntu 18.04+, Debian 10+)
- macOS (10.15+, including Apple Silicon)
- Windows 10+ (WSL2 recommended)

**Hardware:**
- **Disk Space:** 5-10 GB (includes ML models and cache)
- **RAM:** 8 GB minimum, 16 GB recommended for large documents
- **GPU:** Optional, CUDA 11.8 or 12.1 for GPU acceleration

### Installation Options

#### Option 1: Automated Installation (Recommended)

Use the interactive installation script:

```bash
# Navigate to repository
cd SIN_CARRETA

# Run installation script
bash scripts/install_verified.sh

# Follow the prompts to select:
# - PyTorch variant (CPU or CUDA)
# - Optional dependencies (dev, prod, security)
```

#### Option 2: Manual Installation with Requirements Structure

For more control, use the new structured requirements:

```bash
# 1. Create virtual environment with Python 3.10-3.12
python3.10 -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# 2. Upgrade pip
python -m pip install --upgrade pip

# 3. Choose your installation variant:

# For CPU-only (development, CI/CD):
pip install -r requirements/torch-cpu.txt --extra-index-url https://download.pytorch.org/whl/cpu

# For CUDA 11.8 (NVIDIA GPU):
pip install -r requirements/torch-cuda.txt --extra-index-url https://download.pytorch.org/whl/cu118

# For CUDA 12.1 (NVIDIA GPU):
pip install -r requirements/torch-cuda.txt --extra-index-url https://download.pytorch.org/whl/cu121

# 4. Install spaCy models
python -m spacy download es_core_news_sm

# 5. Verify installation
python scripts/validate_continuous.py
```

#### Option 3: Development Installation

For contributors and developers:

```bash
# Install with development dependencies
pip install -r requirements/dev.txt --extra-index-url https://download.pytorch.org/whl/cpu

# Install pre-commit hooks
pre-commit install

# Run full validation
python scripts/validate_continuous.py --all
```

#### Option 4: Production Installation

For production deployments:

```bash
# Install with production dependencies (GPU)
pip install -r requirements/prod.txt --extra-index-url https://download.pytorch.org/whl/cu118

# Verify no conflicts
python scripts/check_conflicts.py

# Generate compatibility certificate
python scripts/generate_certificate.py
```

### Dependency Management Tools

The system now includes industrial-grade dependency management:

**1. Python Version Enforcement**
```bash
# Check Python version compatibility
python scripts/check_python_version.py
```

**2. Import Analysis**
```bash
# Analyze all Python imports in the codebase
python scripts/analyze_imports.py --output import_analysis.json
```

**3. Conflict Detection**
```bash
# Check for dependency conflicts and version issues
python scripts/check_conflicts.py
```

**4. Compatibility Certificate**
```bash
# Generate cryptographic proof of system compatibility
python scripts/generate_certificate.py
# Creates: certificates/compatibility_certificate.{json,md}
```

**5. Continuous Validation**
```bash
# Run all validation checks (for pre-commit/CI)
python scripts/validate_continuous.py --all
```

### Requirements File Structure

The system uses a modular requirements structure:

```
requirements/
‚îú‚îÄ‚îÄ base.txt          # Core dependencies (always required)
‚îú‚îÄ‚îÄ torch-cpu.txt     # CPU-only PyTorch (dev/CI)
‚îú‚îÄ‚îÄ torch-cuda.txt    # GPU PyTorch (production)
‚îú‚îÄ‚îÄ dev.txt           # Development tools (pytest, mypy, black)
‚îú‚îÄ‚îÄ test.txt          # Testing dependencies only
‚îú‚îÄ‚îÄ prod.txt          # Production deployment (FastAPI, Celery)
‚îî‚îÄ‚îÄ security.txt      # Security scanning tools
```

### Verification Steps

After installation, verify your setup:

```bash
# 1. Check Python version
python scripts/check_python_version.py

# 2. Verify critical imports
python -c "import numpy, torch, transformers, spacy; print('‚úì All critical imports OK')"

# 3. Check for conflicts
python scripts/check_conflicts.py

# 4. Run validation suite
python scripts/validate_continuous.py

# 5. Generate certificate (optional)
python scripts/generate_certificate.py
```

### Troubleshooting

**Python Version Issues:**
```bash
# Check current version
python --version

# If wrong version, use pyenv:
pyenv install 3.10.13
pyenv local 3.10.13

# Or use conda:
conda create -n miniminimoon python=3.10
conda activate miniminimoon
```

**Dependency Conflicts:**
```bash
# Check for conflicts
python scripts/check_conflicts.py

# If conflicts found, reinstall with pinned versions:
pip install --force-reinstall -r requirements/torch-cpu.txt
```

**Import Errors:**
```bash
# Analyze imports to find issues
python scripts/analyze_imports.py

# Check specific module
python -c "import <module_name>; print(<module_name>.__version__)"
```

**CUDA Issues:**
```bash
# Check CUDA availability
python -c "import torch; print('CUDA available:', torch.cuda.is_available())"

# Verify CUDA version
python -c "import torch; print('CUDA version:', torch.version.cuda)"
```

### Legacy Installation (Backward Compatible)

The legacy installation method using `requirements.txt` is still supported:

### Legacy Installation (Backward Compatible)

The legacy installation method using `requirements.txt` is still supported:

#### Requisitos Previos

**Sistema Operativo:**
- Linux (Ubuntu 18.04+, Debian 10+)
- macOS (10.15+, incluye Apple Silicon)
- Windows 10+ (con WSL2 recomendado)

**Python Version:**
- **Python 3.10** (REQUERIDO - versi√≥n exacta)
- Otras versiones NO soportadas debido a compatibilidad con NumPy >=1.21.0 y modelos de embeddings

**Espacio en Disco:**
- M√≠nimo: 5 GB
- Recomendado: 10 GB (incluye modelos de NLP y cach√©)

**Memoria RAM:**
- M√≠nimo: 8 GB
- Recomendado: 16 GB (para planes grandes >100 p√°ginas)

### Paso 1: Verificar Python 3.10

```bash
# Verificar versi√≥n de Python
python3.10 --version

# Si no est√° instalado:
# Ubuntu/Debian:
sudo apt update
sudo apt install python3.10 python3.10-venv python3.10-dev

# macOS (con Homebrew):
brew install python@3.10

# Verificar que est√© disponible
which python3.10
```

### Paso 2: Clonar el Repositorio

```bash
# Clonar repositorio
git clone https://github.com/ANITALAVALATINACONPRISA/SIN_CARRETA.git
cd SIN_CARRETA

# Verificar que est√°s en el directorio correcto
pwd  # Debe mostrar: /ruta/a/SIN_CARRETA
ls   # Debe mostrar: README.md, requirements.txt, miniminimoon_orchestrator.py, etc.
```

### Paso 3: Crear Entorno Virtual (Python 3.10)

```bash
# Crear entorno virtual con Python 3.10
python3.10 -m venv venv

# Activar entorno virtual
# En Linux/macOS:
source venv/bin/activate

# En Windows (PowerShell):
# .\venv\Scripts\Activate.ps1

# Verificar que Python 3.10 est√° activo
python --version  # Debe mostrar: Python 3.10.x
```

### Paso 4: Actualizar pip, setuptools y wheel

```bash
# Actualizar herramientas de instalaci√≥n
python -m pip install --upgrade pip setuptools wheel

# Verificar versiones actualizadas
pip --version  # Debe mostrar pip 23.0 o superior
```

### Paso 5: Instalar Dependencias Base

```bash
# Instalar todas las dependencias del proyecto
pip install -r requirements.txt

# Tiempo estimado: 5-10 minutos
# Si encuentras errores, ver secci√≥n de Troubleshooting abajo
```

### Paso 6: Instalar Dependencias de Desarrollo (Opcional)

```bash
# Solo si necesitas ejecutar tests o desarrollo
pip install -r requirements-dev.txt

# Incluye: pytest, mypy, black, flake8, pylint
```

### Paso 7: Descargar Modelos de NLP

```bash
# Descargar modelos de spaCy (espa√±ol)
python -m spacy download es_core_news_sm
python -m spacy download es_core_news_md

# Descargar datos de NLTK
python -c "import nltk; nltk.download('punkt'); nltk.download('stopwords'); nltk.download('wordnet'); nltk.download('averaged_perceptron_tagger')"

# Verificar instalaci√≥n de modelos
python -c "import spacy; nlp = spacy.load('es_core_news_sm'); print('‚úì spaCy modelo cargado correctamente')"
```

### Paso 8: Crear Estructura de Directorios

```bash
# Crear directorios necesarios para el sistema
mkdir -p artifacts config logs output data

# Verificar estructura
ls -la | grep -E "artifacts|config|logs|output|data"
```

### Paso 9: Verificar Archivos de Configuraci√≥n

```bash
# Verificar que existan los archivos de configuraci√≥n cr√≠ticos
ls -la config/ | grep -E "decalogo_industrial|dnp-standards|RUBRIC_SCORING"

# O verificar en el directorio ra√≠z:
ls -la | grep -E "decalogo_industrial|dnp-standards|RUBRIC_SCORING"

# Archivos requeridos:
# - decalogo_industrial.json (o decalogo-industrial.latest.clean.json)
# - dnp-standards.latest.clean.json
# - RUBRIC_SCORING.json (o rubric_scoring.json)
```

**‚ö†Ô∏è Si faltan archivos:** El sistema no podr√° ejecutarse sin estos archivos. Deben ser proporcionados por el administrador del proyecto.

### Paso 10: Ejecutar Verificaci√≥n de Compatibilidad

```bash
# Verificar que todo est√° correctamente instalado
python python_310_compatibility_checker.py

# Output esperado:
# ‚úì Python 3.10.x detected
# ‚úì NumPy version compatible
# ‚úì All dependencies installed
# ‚úì System ready for operation
```

### Paso 11: Verificar Instalaci√≥n del Sistema

```bash
# Verificar que todos los m√≥dulos se pueden importar
python -c "from miniminimoon_orchestrator import CanonicalDeterministicOrchestrator; print('‚úì Orchestrator OK')"
python -c "from plan_processor import PlanProcessor; print('‚úì Plan Processor OK')"
python -c "from document_segmenter import DocumentSegmenter; print('‚úì Document Segmenter OK')"
python -c "from plan_sanitizer import PlanSanitizer; print('‚úì Plan Sanitizer OK')"
python -c "from embedding_model import EmbeddingModel; print('‚úì Embedding Model OK')"

# Si todos muestran "‚úì ... OK", la instalaci√≥n fue exitosa
```

### Instalaci√≥n Automatizada (Script)

Si prefieres una instalaci√≥n automatizada, puedes usar el script `setup_environment.sh`:

```bash
# Hacer ejecutable el script
chmod +x setup_environment.sh

# Ejecutar script de instalaci√≥n
./setup_environment.sh
```

**El script automatiza:**
- ‚úì Verificaci√≥n de Python 3.10
- ‚úì Creaci√≥n de entorno virtual
- ‚úì Instalaci√≥n de dependencias (base + dev opcional)
- ‚úì Descarga de modelos NLP (spaCy + NLTK)
- ‚úì Creaci√≥n de estructura de directorios
- ‚úì Verificaci√≥n de archivos de configuraci√≥n
- ‚úì Tests b√°sicos de verificaci√≥n (opcional)

**Interacci√≥n durante el script:**

```bash
# El script preguntar√°:
¬øDeseas instalar dependencias de desarrollo? (y/n): y
¬øDeseas ejecutar tests b√°sicos de verificaci√≥n? (y/n): y
```

**Output esperado al finalizar:**

```
==========================================
Setup completado exitosamente!
==========================================

Para activar el entorno en el futuro:
  source venv/bin/activate

Para ejecutar el sistema:
  1. Congelar configuraci√≥n:
     python miniminimoon_orchestrator.py freeze ./config/

  2. Ejecutar evaluaci√≥n:
     python miniminimoon_orchestrator.py evaluate ./config/ plan.pdf ./output/

  3. Verificar reproducibilidad:
     python miniminimoon_orchestrator.py verify ./config/ plan.pdf --runs 3

Documentaci√≥n completa en:
  - FLUJOS_CRITICOS_GARANTIZADOS.md
  - ARCHITECTURE.md
```

**‚ö†Ô∏è Nota para Windows:** El script `setup_environment.sh` es para Linux/macOS. Para Windows, usa `setup_environment.bat` o sigue los pasos manuales en PowerShell.

---

## üöÄ Gu√≠a de Implementaci√≥n (Workflow Completo)

Una vez completada la instalaci√≥n, sigue estos pasos para implementar y usar el sistema:

### Paso 1: Congelar Configuraci√≥n (Gate #1) - OBLIGATORIO

Este paso es **CR√çTICO** y debe ejecutarse antes de cualquier evaluaci√≥n.

```bash
# Activar entorno virtual si no est√° activo
source venv/bin/activate

# Congelar configuraci√≥n (crea snapshot inmutable)
python miniminimoon_cli.py freeze

# O usando el orquestador directamente:
python miniminimoon_orchestrator.py freeze ./config/
```

**¬øQu√© hace esto?**
- Crea `.immutability_snapshot.json` con hash SHA-256 de todos los archivos de configuraci√≥n
- Garantiza que la configuraci√≥n no cambie entre ejecuciones
- Es requisito obligatorio para Gate #1 (primera validaci√≥n)

**Output esperado:**
```
‚úì Configuration frozen successfully
  Hash: a3f8d2e1b4c5a9f2d8e6c4a1b7f3d9e5
  Files: ['decalogo_industrial.json', 'dnp-standards.latest.clean.json', 'RUBRIC_SCORING.json']
  Snapshot saved: .immutability_snapshot.json
```

### Paso 2: Verificar Estado del Sistema (Pre-Ejecuci√≥n)

```bash
# Verificar sistema con validaci√≥n end-to-end
python test_validation_end_to_end.py

# O verificar usando el CLI con diagn√≥stico
python miniminimoon_cli.py diagnostic

# O verificar que el sistema est√° operativo
python -c "from system_validators import SystemHealthValidator; print('‚úì System validators ready')"
```

### Paso 3: Ejecutar Primera Evaluaci√≥n de PDM

```bash
# Evaluaci√≥n completa con validaci√≥n estricta
python miniminimoon_cli.py evaluate --plan path/to/tu_plan.pdf --strict

# O usando el orquestador con m√°s control:
python miniminimoon_orchestrator.py evaluate ./config/ tu_plan.pdf ./output/

# Tiempo estimado: 45-60 segundos para plan de ~50 p√°ginas
```

**Argumentos:**
- `--plan`: Ruta al archivo PDF del Plan de Desarrollo Municipal
- `--strict`: Modo estricto (activa todas las validaciones)
- `./config/`: Directorio con archivos de configuraci√≥n
- `./output/`: Directorio donde se guardar√°n los resultados

**Artifacts Generados (en `output/` o `artifacts/`):**

```
output/
‚îú‚îÄ‚îÄ answers_report.json           # ‚≠ê Reporte completo con 300 preguntas respondidas
‚îú‚îÄ‚îÄ answers_sample.json           # Muestra de las primeras 10 respuestas
‚îú‚îÄ‚îÄ evidence_registry.json        # Registro √∫nico de toda la evidencia recolectada
‚îú‚îÄ‚îÄ flow_runtime.json             # Trace completo de ejecuci√≥n (orden + contratos I/O)
‚îú‚îÄ‚îÄ coverage_report.json          # Cobertura: qu√© preguntas tienen evidencia
‚îú‚îÄ‚îÄ final_results.json            # Resultados consolidados + hashes (evidence_hash, flow_hash)
‚îî‚îÄ‚îÄ module_to_questions_matrix.csv # Matriz de trazabilidad: m√≥dulo ‚Üí pregunta ‚Üí evidencia
```

### Paso 4: Inspeccionar Resultados

```bash
# Ver resumen de resultados
cat output/final_results.json | python -m json.tool | head -50

# Ver muestra de respuestas
cat output/answers_sample.json | python -m json.tool

# Ver evidencia recolectada
cat output/evidence_registry.json | python -m json.tool | head -100

# Verificar cobertura de preguntas
python -c "import json; data=json.load(open('output/coverage_report.json')); print(f'Preguntas respondidas: {data[\"coverage_summary\"][\"total_answered\"]}/300')"
```

**Estructura de una Respuesta (ejemplo):**

```json
{
  "question_id": "DE-1-Q4",
  "dimension": "DE-1",
  "question_text": "¬øSe especifican l√≠neas base cuantitativas?",
  "evidence_ids": ["resp_abc123", "feas_def456"],
  "confidence": 0.85,
  "score": 2.5,
  "reasoning": "Evidencia s√≥lida de l√≠neas base en 3 programas: Educaci√≥n (45% cobertura 2023), Salud (62% atenci√≥n 2023), Infraestructura (78% v√≠as pavimentadas 2023)...",
  "rubric_weight": 0.15,
  "supporting_quotes": [
    "L√≠nea base 2023: 45% cobertura educativa en zona rural",
    "Meta 2027: Incrementar a 75% cobertura educativa"
  ],
  "caveats": ["Basado en 2 fuentes de evidencia", "No se encontr√≥ l√≠nea base para programa de medio ambiente"]
}
```

### Paso 5: Verificar Reproducibilidad (Gate #3) - CR√çTICO

Este paso valida que el sistema es **determinista**: mismo input = mismo output.

```bash
# Ejecutar pipeline 3 veces con el mismo input
python miniminimoon_orchestrator.py verify ./config/ tu_plan.pdf --runs 3

# O manualmente:
for i in {1..3}; do
  python miniminimoon_cli.py evaluate --plan tu_plan.pdf --output run_${i}.json
done

# Comparar hashes (deben ser ID√âNTICOS)
python -c "
import json
hashes = []
for i in range(1, 4):
    with open(f'run_{i}.json') as f:
        data = json.load(f)
        hashes.append(data['evidence_hash'])
print('Evidence hashes:', hashes)
print('Todas id√©nticas:', len(set(hashes)) == 1)
"
```

**Output esperado:**
```
‚úì Run 1 completed - evidence_hash: a3f8d2e1b4c5...
‚úì Run 2 completed - evidence_hash: a3f8d2e1b4c5...
‚úì Run 3 completed - evidence_hash: a3f8d2e1b4c5...
‚úì DETERMINISM VERIFIED: All hashes identical
‚úì Gate #3 PASSED
```

**‚ö†Ô∏è Si los hashes NO son id√©nticos:** Hay un problema de no-determinismo. Reportar como bug.

### Paso 6: Validar Alineaci√≥n de R√∫brica (Gate #5)

```bash
# Verificar que hay correspondencia 1:1 entre preguntas y pesos de r√∫brica
python miniminimoon_cli.py rubric-check \
    output/answers_report.json \
    config/RUBRIC_SCORING.json
```

**Output esperado (PASSING):**
```
================================================================================
RUBRIC VALIDATION REPORT
================================================================================
‚úì Total questions in answers_report: 300
‚úì Total weights in rubric: 300
‚úì All questions have corresponding weights
‚úì All weights have corresponding questions
‚úì No missing questions
‚úì No extra weights
================================================================================
‚úì RUBRIC VALIDATION PASSED - Gate #5 ‚úì
================================================================================
```

**Output esperado (FAILING):**
```
================================================================================
RUBRIC VALIDATION REPORT
================================================================================
‚úó Total questions in answers_report: 300
‚úó Total weights in rubric: 295
‚úó MISSING questions (no weight): ['DE-3-Q14', 'DE-5-Q22', ...]
‚úó EXTRA weights (no question): []
================================================================================
‚úó RUBRIC VALIDATION FAILED - Gate #5 ‚úó
Exit code: 3
================================================================================
```

**Si falla:** Corregir `RUBRIC_SCORING.json` para a√±adir/eliminar pesos seg√∫n sea necesario.

### Paso 7: Generar Matriz de Trazabilidad

```bash
# Generar matriz completa: m√≥dulo ‚Üí pregunta ‚Üí evidencia
python miniminimoon_cli.py trace-matrix

# Output: artifacts/module_to_questions_matrix.csv
```

Este archivo CSV muestra qu√© m√≥dulos del pipeline generaron evidencia para qu√© preguntas, permitiendo auditor√≠a completa.

### Paso 8: Verificaci√≥n Post-Ejecuci√≥n Completa

```bash
# Ejecutar todas las verificaciones post-ejecuci√≥n
python miniminimoon_cli.py verify

# Este comando ejecuta:
# - Verificaci√≥n de Gates #3, #4, #5
# - Validaci√≥n de contratos I/O
# - Verificaci√≥n de orden can√≥nico
# - Chequeo de cobertura ‚â•300 preguntas
```

---

## üîß Uso Program√°tico (API Python)

Para integrar MINIMINIMOON en tu propio c√≥digo:

```python
from miniminimoon_orchestrator import CanonicalDeterministicOrchestrator

# Inicializar orquestador con validaci√≥n habilitada
orchestrator = CanonicalDeterministicOrchestrator(
    config_dir="./config",           # Directorio con archivos JSON
    enable_validation=True,           # Activar validaci√≥n de gates
    flow_doc_path="tools/flow_doc.json",  # Orden can√≥nico documentado
    log_level="INFO"                  # DEBUG, INFO, WARNING, ERROR
)

# Ejecutar pipeline completo de forma determinista
results = orchestrator.process_plan_deterministic("path/to/plan.pdf")

# Acceder a resultados
print(f"Evidence hash: {results['evidence_hash']}")
print(f"Flow hash: {results['validation']['flow_hash']}")
print(f"Total preguntas: {results['evaluations']['answers_report']['summary']['total_questions']}")

# Acceder a respuestas individuales
answers = results['evaluations']['answers_report']['answers']
for answer in answers[:5]:  # Primeras 5 respuestas
    print(f"Q: {answer['question_id']} - Score: {answer['score']}")

# Acceder a evidencia
evidence_store = results['evidence_registry']
print(f"Total evidencias: {len(evidence_store['evidence_by_type'])}")

# Guardar resultados
import json
with open('my_results.json', 'w', encoding='utf-8') as f:
    json.dump(results, f, indent=2, ensure_ascii=False)
```

---

## üÜò Troubleshooting (Soluci√≥n de Problemas)

### Problema 1: Error al instalar dependencias

**S√≠ntoma:**
```
ERROR: Could not find a version that satisfies the requirement...
```

**Soluciones:**

```bash
# Soluci√≥n 1: Verificar versi√≥n de Python
python --version  # DEBE ser 3.10.x

# Soluci√≥n 2: Limpiar cach√© de pip
pip cache purge
pip install -r requirements.txt --no-cache-dir

# Soluci√≥n 3: Instalar en grupos peque√±os
pip install numpy scipy scikit-learn
pip install pandas
pip install torch --index-url https://download.pytorch.org/whl/cpu  # CPU-only (m√°s ligero)
pip install sentence-transformers
pip install spacy networkx matplotlib
```

### Problema 2: Error "No space left on device"

**S√≠ntoma:**
```
[Errno 28] No space left on device
```

**Soluciones:**

```bash
# Ver espacio disponible
df -h

# Limpiar cach√© de pip
pip cache purge

# Instalar torch CPU-only (m√°s ligero: ~200MB vs ~2GB)
pip uninstall torch
pip install torch --index-url https://download.pytorch.org/whl/cpu

# Ver espacio usado por venv
du -sh venv/

# Si necesario, mover a disco con m√°s espacio
mv venv /otro/disco/con/espacio/
ln -s /otro/disco/con/espacio/venv venv
```

### Problema 3: Error al importar m√≥dulos

**S√≠ntoma:**
```
ImportError: cannot import name 'CanonicalDeterministicOrchestrator'
ModuleNotFoundError: No module named 'plan_processor'
```

**Soluciones:**

```bash
# Verificar que est√°s en el directorio correcto
pwd  # Debe mostrar: /ruta/a/SIN_CARRETA

# Verificar que el entorno virtual est√° activo
which python  # Debe mostrar: /ruta/a/SIN_CARRETA/venv/bin/python

# Reinstalar dependencias
pip install -r requirements.txt --force-reinstall

# Verificar archivos Python existen
ls -la *.py | grep -E "orchestrator|processor|segmenter|sanitizer"
```

### Problema 4: Error "No frozen config snapshot"

**S√≠ntoma:**
```
RuntimeError: Configuration must be frozen before execution (Gate #1)
File not found: .immutability_snapshot.json
```

**Soluci√≥n:**

```bash
# Ejecutar freeze antes de cualquier evaluaci√≥n
python miniminimoon_cli.py freeze

# Verificar que se cre√≥ el snapshot
ls -la .immutability_snapshot.json
cat .immutability_snapshot.json | python -m json.tool
```

### Problema 5: Modelos de spaCy no encontrados

**S√≠ntoma:**
```
OSError: [E050] Can't find model 'es_core_news_sm'
```

**Soluci√≥n:**

```bash
# Descargar modelo nuevamente
python -m spacy download es_core_news_sm

# Verificar instalaci√≥n
python -c "import spacy; nlp = spacy.load('es_core_news_sm'); print('OK')"

# Si persiste, instalar manualmente
pip install https://github.com/explosion/spacy-models/releases/download/es_core_news_sm-3.8.0/es_core_news_sm-3.8.0-py3-none-any.whl
```

### Problema 6: Archivos de configuraci√≥n faltantes

**S√≠ntoma:**
```
FileNotFoundError: [Errno 2] No such file or directory: 'decalogo_industrial.json'
```

**Soluci√≥n:**

```bash
# Verificar ubicaci√≥n de archivos
find . -name "decalogo*.json"
find . -name "dnp-standards*.json"
find . -name "rubric*.json"

# Copiar a ubicaci√≥n esperada (si est√°n en subdirectorios)
cp config/decalogo-industrial.latest.clean.json decalogo_industrial.json
cp config/dnp-standards.latest.clean.json .
cp config/rubric_scoring.json RUBRIC_SCORING.json

# O crear enlaces simb√≥licos
ln -s config/decalogo-industrial.latest.clean.json decalogo_industrial.json
```

### Problema 7: Hashes no reproducibles (Gate #3 falla)

**S√≠ntoma:**
```
‚úó DETERMINISM CHECK FAILED
Run 1 hash: a3f8d2e1...
Run 2 hash: b4c5f6d7...
Run 3 hash: c8d9e0f1...
```

**Soluci√≥n:**

```bash
# Verificar que determinism_guard est√° activo
python -c "from determinism_guard import verify_determinism; verify_determinism()"

# Ejecutar con modo debug
python miniminimoon_cli.py evaluate --plan test.pdf --debug

# Revisar logs para identificar fuente de no-determinismo
cat logs/miniminimoon_*.log | grep -i "random\|seed\|nondetermin"
```

### Problema 8: Validaci√≥n de r√∫brica falla (Gate #5)

**S√≠ntoma:**
```
‚úó RUBRIC VALIDATION FAILED
Missing questions: ['DE-3-Q14', 'DE-5-Q22']
Extra weights: ['DE-1-Q99']
```

**Soluci√≥n:**

```bash
# Ejecutar rubric_check para ver detalles
python miniminimoon_cli.py rubric-check

# Editar RUBRIC_SCORING.json para corregir
# - A√±adir pesos para preguntas faltantes
# - Eliminar pesos extra

# Verificar formato JSON
python -m json.tool RUBRIC_SCORING.json > /dev/null
echo "JSON v√°lido"

# Volver a ejecutar validaci√≥n
python miniminimoon_cli.py rubric-check
```

### Problema 9: Performance lento (>120 segundos)

**S√≠ntoma:**
```
Evaluation took 180 seconds (expected: 45-60s)
```

**Soluciones:**

```bash
# Verificar uso de CPU/memoria durante ejecuci√≥n
htop  # o top

# Usar CPU-only torch si no tienes GPU
pip uninstall torch
pip install torch --index-url https://download.pytorch.org/whl/cpu

# Reducir verbosity de logs
python miniminimoon_cli.py evaluate --plan test.pdf --log-level WARNING

# Verificar que no hay procesos en background
ps aux | grep python
```

### Problema 10: Pytest/Tests fallan

**S√≠ntoma:**
```
test_critical_flows.py::test_flow_1 FAILED
```

**Soluciones:**

```bash
# Verificar que pytest est√° instalado
pip install pytest pytest-cov

# Ejecutar tests con verbose
python -m pytest -v test_critical_flows.py

# Ejecutar solo tests cr√≠ticos
python -m pytest -k "critical" -v

# Ver output completo de errores
python -m pytest --tb=long test_critical_flows.py
```

### Problema 11: Error "No frozen config snapshot"

**S√≠ntoma:**
```
RuntimeError: Configuration must be frozen before execution (Gate #1)
File not found: .immutability_snapshot.json
```

**Soluci√≥n:**

```bash
python miniminimoon_cli.py freeze
```

### Problema 12: Error "Flow order does not match canonical documentation"

**Causa:** Modificaci√≥n del orden de ejecuci√≥n en el orquestador

**Soluci√≥n:** 

Revisar que el orden en `miniminimoon_orchestrator.py` coincida con `tools/flow_doc.json`. No modificar el orden can√≥nico sin autorizaci√≥n.

### Problema 13: Error "decalogo_pipeline_orchestrator is DEPRECATED"

**Causa:** Intento de usar orquestador deprecado

**Soluci√≥n:**

```python
# ‚ùå PROHIBIDO
from decalogo_pipeline_orchestrator import DecalogoPipelineOrchestrator

# ‚úÖ CORRECTO
from miniminimoon_orchestrator import CanonicalDeterministicOrchestrator
```

Ver `DEPRECATIONS.md` para detalles completos de migraci√≥n.

---

## üìä Salidas del Sistema

### Artifacts Generados

```
artifacts/
‚îú‚îÄ‚îÄ answers_report.json           # Reporte completo 300 preguntas
‚îú‚îÄ‚îÄ answers_sample.json           # Muestra primeras 10 respuestas
‚îú‚îÄ‚îÄ flow_runtime.json             # Orden de ejecuci√≥n + contratos
‚îú‚îÄ‚îÄ evidence_registry.json        # Registro completo de evidencia
‚îú‚îÄ‚îÄ coverage_report.json          # Cobertura por pregunta
‚îú‚îÄ‚îÄ final_results.json            # Resultados consolidados + hashes
‚îî‚îÄ‚îÄ module_to_questions_matrix.csv # Matriz de trazabilidad
```

### Estructura de Respuesta (ejemplo)

```json
{
  "question_id": "DE-1-Q4",
  "dimension": "DE-1",
  "evidence_ids": ["resp_abc123", "feas_def456"],
  "confidence": 0.85,
  "score": 2.5,
  "reasoning": "Evidencia s√≥lida de l√≠neas base en 3 programas...",
  "rubric_weight": 0.15,
  "supporting_quotes": [
    "L√≠nea base 2023: 45% cobertura educativa...",
    "Meta 2027: 75% cobertura..."
  ],
  "caveats": ["Basado en 2 fuentes de evidencia"]
}
```

---

## üîí Principios de Dise√±o

### 1. Determinismo Garantizado
- Seeds fijos: `random=42`, `numpy=42`, `torch=42`
- Sin I/O no determinista durante evaluaci√≥n
- Orden can√≥nico documentado y verificado

### 2. Single Source of Truth
- **Evidence Registry √∫nico** para toda evidencia
- No recalcular outputs entre evaluadores
- Provenance completo de toda evidencia

### 3. Trazabilidad Total
- Cada respuesta vinculada a `evidence_ids`
- Cada evidencia con `source_segment_ids`
- Hash determinista para reproducibilidad

### 4. Validaci√≥n Autom√°tica
- Pre-checks antes de ejecuci√≥n (config, freeze, contratos)
- Post-checks despu√©s de ejecuci√≥n (cobertura, hashes, r√∫brica)
- CI/CD gates obligatorios

### 5. No Rutas Paralelas
- **UN SOLO** orquestador: `CanonicalDeterministicOrchestrator`
- Orquestador deprecado bloqueado con `RuntimeError`
- Enforcement en CI/CD

---

## ‚ö†Ô∏è M√≥dulos Deprecados (PROHIBIDO)

### ‚ùå `decalogo_pipeline_orchestrator.py`

**Estado:** DEPRECATED - Lanza `RuntimeError` al importar

**Raz√≥n:**
- Crea rutas de ejecuci√≥n paralelas
- Fragmenta evidence registry
- Bypasea gates de validaci√≥n
- Rompe audit trail

**Migraci√≥n obligatoria:**
```python
# ‚ùå PROHIBIDO
from decalogo_pipeline_orchestrator import DecalogoPipelineOrchestrator

# ‚úÖ CORRECTO
from miniminimoon_orchestrator import CanonicalDeterministicOrchestrator
```

Ver `DEPRECATIONS.md` para detalles completos de migraci√≥n.

---

## üß™ Testing y Verificaci√≥n

### Verificaci√≥n Completa del Sistema

```bash
# Verificar todos los flujos con validaci√≥n end-to-end
python test_validation_end_to_end.py

# O usar el CLI con diagn√≥stico completo
python miniminimoon_cli.py diagnostic

# O verificar componentes individuales
python -m pytest test_plan_sanitizer.py test_document_segmenter.py test_teoria_cambio.py -v
```

### Tests Unitarios por Componente

```bash
# Tests individuales
python -m pytest test_plan_sanitizer.py
python -m pytest test_feasibility_scorer.py
python -m pytest test_teoria_cambio.py
python -m pytest test_dag_validation.py
```

### Triple-Run para Verificar Determinismo

```bash
# Ejecutar 3 veces y verificar hashes id√©nticos
for i in {1..3}; do
  python miniminimoon_cli.py evaluate --plan test.pdf > run_$i.json
done

# Comparar evidence_hash y flow_hash (deben ser id√©nticos)
```

---

## üìà Performance y Optimizaciones

### Optimizaciones Implementadas

- **Contract validation caching**: 37% mejora (7.9ms ‚Üí <5ms)
- **Mathematical invariant optimizations**: 43% mejora en PERMUTATION_INVARIANCE
- **Budget monotonicity**: 40% mejora (0.25ms ‚Üí <0.15ms)
- **CI/CD performance gate**: Bloquea PRs que excedan presupuesto >10%
- **Soak test 4 horas**: Detecci√≥n de memory leaks

### M√©tricas de Performance

```
Pipeline completo (plan ~50 p√°ginas): ~45-60 segundos
- Sanitizaci√≥n: <1s
- Segmentaci√≥n: 2-3s
- Embeddings: 15-20s (modelo transformer)
- Detectores (6 m√≥dulos): 10-15s
- Teor√≠a cambio + DAG: 5-8s
- Evaluadores: 8-12s
- Answer assembly: <2s
```

---

## üìä Visual Architecture Diagrams

The MINIMINIMOON system architecture is documented through **SEVEN hyper-modern, futuristic neo-punk diagrams** that provide a compelling visual narrative of the unified evaluation architecture. Each diagram uses consistent color schemes and clear directional flows with cardinality annotations.

### 1Ô∏è‚É£ High-Level System Architecture

**Location**: `docs/diagrams/01_system_architecture.png`

```mermaid
graph TB
    CLI[üñ•Ô∏è CLI Interface<br/>miniminimoon_cli.py] --> Unified[üîÑ Unified Evaluation Pipeline<br/>Pre-Validation + Post-Validation]
    Unified --> Orchestrator[‚öôÔ∏è Canonical Orchestrator<br/>15-Stage Pipeline]
    Orchestrator --> Artifacts[üì¶ Artifacts<br/>JSON Reports]
    
    style CLI fill:#ff00ff,stroke:#ff00ff,color:#000
    style Unified fill:#00ff88,stroke:#00ff88,color:#000
    style Orchestrator fill:#00d4ff,stroke:#00d4ff,color:#000
    style Artifacts fill:#ffff00,stroke:#ffff00,color:#000
```

**Description**: This diagram shows the high-level flow from CLI through `unified_evaluation_pipeline` to `miniminimoon_orchestrator` and artifact generation. It illustrates the single entry point design principle and the orchestrator's role as the central processing hub.

**References**: 
- [FLUJOS_CRITICOS_GARANTIZADOS.md](FLUJOS_CRITICOS_GARANTIZADOS.md) - Flow #18 (Unified Pipeline)
- [ARCHITECTURE.md](ARCHITECTURE.md) - Core Components section

---

### 2Ô∏è‚É£ Detailed Evidence Data Flow

**Location**: `docs/diagrams/02_data_flow.png`

```mermaid
graph TB
    subgraph Detectors[üìä DETECTORS Stage 5-11]
        D1[Responsibility]
        D2[Contradiction]
        D3[Monetary]
        D4[Feasibility]
        D5[Causal Pattern]
        D6[Teor√≠a Cambio]
        D7[DAG Validation]
    end
    
    Registry[üì¶ Evidence Registry<br/>Stage 12<br/>FAN-IN N:1]
    
    subgraph Evaluators[üéì EVALUATORS Stage 13-14]
        E1[Dec√°logo Evaluator]
        E2[Questionnaire Engine]
    end
    
    Assembler[üîß Answer Assembler<br/>Stage 15<br/>300 Questions]
    
    D1 & D2 & D3 & D4 & D5 & D6 & D7 --> Registry
    Registry --> E1 & E2
    Registry --> Assembler
    E1 & E2 --> Assembler
    
    style Registry fill:#00ffff,stroke:#00ffff,color:#000
    style Assembler fill:#00ff88,stroke:#00ff88,color:#000
```

**Description**: Illustrates how evidence flows from 7 parallel detectors (Stage 5-11) through the **Evidence Registry** (Stage 12 - FAN-IN N:1) to evaluators and finally to the **Answer Assembler** for the 300-question evaluation. This diagram emphasizes the "Single Source of Truth" principle.

**References**: 
- [FLUJOS_CRITICOS_GARANTIZADOS.md](FLUJOS_CRITICOS_GARANTIZADOS.md) - Flows #5-#15
- [ARCHITECTURE.md](ARCHITECTURE.md) - Evidence Registry component

---

### 3Ô∏è‚É£ Validation Gates Diagram

**Location**: `docs/diagrams/03_validation_gates.png`

```mermaid
graph TB
    subgraph Pre[‚ö° PRE-EXECUTION GATES]
        G1[üîí Gate 1: Freeze<br/>Config Immutability]
        G2[üìã Gate 2: Flow Order<br/>Canonical Validation]
        G6[‚ùå Gate 6: No Deprecated<br/>Single Path Enforcement]
        G1 --> G2 --> G6
    end
    
    Pipeline[‚öôÔ∏è CANONICAL PIPELINE<br/>15 Stages]
    
    subgraph Post[‚ö° POST-EXECUTION GATES]
        G3[üîê Gate 3: Determinism<br/>Hash Stability]
        G4[üìä Gate 4: Coverage<br/>‚â•300 Questions]
        G5[üìè Gate 5: Rubric<br/>1:1 Alignment]
        G3 --> G4 --> G5
    end
    
    G6 --> Pipeline --> G3
    G5 --> Success[‚úÖ VALIDATION PASSED]
    
    style G1 fill:#00ffff,stroke:#00ffff,color:#000
    style G2 fill:#00ffff,stroke:#00ffff,color:#000
    style G6 fill:#00ffff,stroke:#00ffff,color:#000
    style G3 fill:#ff00ff,stroke:#ff00ff,color:#000
    style G4 fill:#ff00ff,stroke:#ff00ff,color:#000
    style G5 fill:#ff00ff,stroke:#ff00ff,color:#000
    style Success fill:#00ff88,stroke:#00ff88,color:#000
```

**Description**: Depicts the 6 acceptance gates split into pre-execution checks (freeze verification, flow order, deprecated module check) and post-execution validation (determinism, coverage, rubric alignment). Shows pass/fail paths and blocking behavior.

**References**: 
- [FLUJOS_CRITICOS_GARANTIZADOS.md](FLUJOS_CRITICOS_GARANTIZADOS.md) - Section 2: Gates de Aceptaci√≥n
- README.md - Gates de Aceptaci√≥n section

---

### 4Ô∏è‚É£ CI/CD Pipeline Visualization

**Location**: `docs/diagrams/04_cicd_pipeline.png`

```mermaid
graph TB
    Trigger[üîî Pull Request] --> Setup[üì¶ Setup<br/>Python + spaCy]
    Setup --> Freeze[üîí Freeze Verification<br/>Gate #1]
    Freeze --> Build[üî® Build<br/>Compile All Modules]
    Build --> Lint[üìè Lint<br/>PEP 8 Check]
    Lint --> Triple[üîÑ Triple-Run<br/>Reproducibility Test]
    Triple --> Unit[üß™ Unit Tests<br/>Component Tests]
    Unit --> Integration[üîó Integration Tests<br/>72 Critical Flows]
    Integration --> Perf[‚ö° Performance Gate<br/>p95 < Budget+10%]
    Perf --> Archive[üì¶ Artifact Archival<br/>30-day Retention]
    Archive --> Success[‚úÖ BUILD SUCCESS<br/>Ready to Merge]
    
    Triple -.Fail.-> Fail[‚ùå BUILD FAILED<br/>Block PR]
    
    style Freeze fill:#ff00ff,stroke:#ff00ff,color:#000
    style Triple fill:#ffff00,stroke:#ffff00,color:#000
    style Success fill:#00ff88,stroke:#00ff88,color:#000
    style Fail fill:#ff0000,stroke:#ff0000,color:#fff
```

**Description**: Complete build workflow showing 9 stages from PR trigger to success/failure. Includes freeze verification, triple-run reproducibility tests (Gate #3), and artifact archival. Highlights critical checkpoints that block PRs on failure.

**References**: 
- [FLUJOS_CRITICOS_GARANTIZADOS.md](FLUJOS_CRITICOS_GARANTIZADOS.md) - Section 9: Garant√≠as de Determinismo
- README.md - Contribuci√≥n > CI/CD Pipeline

---

### 5Ô∏è‚É£ 15-Stage Canonical Pipeline

**Location**: `docs/diagrams/05_15_stage_pipeline.png`

```mermaid
graph TB
    Input[üìÑ Raw PDM Plan] --> S1[Stage 1: Sanitization]
    S1 --> S2[Stage 2: Plan Processing]
    S2 --> S3[Stage 3: Segmentation]
    S3 --> S4[Stage 4: Embeddings]
    
    S4 --> S5[Stage 5: Responsibility]
    S4 --> S6[Stage 6: Contradiction]
    S4 --> S7[Stage 7: Monetary]
    S4 --> S8[Stage 8: Feasibility]
    S4 --> S9[Stage 9: Causal Pattern]
    S4 --> S10[Stage 10: Teor√≠a Cambio]
    S10 --> S11[Stage 11: DAG Validation]
    
    S5 & S6 & S7 & S8 & S9 & S10 & S11 --> S12[üî∑ Stage 12: Evidence Registry<br/>FAN-IN N:1]
    
    S12 --> S13[Stage 13: Dec√°logo Eval]
    S12 --> S14[Stage 14: Questionnaire]
    
    S12 & S13 & S14 --> S15[üî∑ Stage 15: Answer Assembly]
    S15 --> Output[üìÑ 300 Answers Report]
    
    style S12 fill:#00ffff,stroke:#00ffff,color:#000
    style S15 fill:#00ff88,stroke:#00ff88,color:#000
```

**Description**: Sequential view of all 15 pipeline stages organized into 4 phases: Processing (1-11), Evidence Registry (12), Evaluation (13-14), and Assembly (15). Shows fan-out at Stage 4 (detectors) and fan-in at Stage 12 (evidence registry).

**References**: 
- [FLUJOS_CRITICOS_GARANTIZADOS.md](FLUJOS_CRITICOS_GARANTIZADOS.md) - Section 1: Flujos Cr√≠ticos Principales
- [ARCHITECTURE.md](ARCHITECTURE.md) - System Components

---

### 6Ô∏è‚É£ Data Contract Validation

**Location**: `docs/diagrams/06_contract_validation.png`

```mermaid
graph LR
    Input[üì• Input Data] --> TypeCheck[‚úì Type Validation<br/>Schema Conformance]
    TypeCheck --> InvariantCheck[‚àû Mathematical Invariants<br/>PERMUTATION_INVARIANCE<br/>MONOTONICITY<br/>IDEMPOTENCE]
    InvariantCheck --> SemanticCheck[üéØ Semantic Validation<br/>Domain Rules]
    SemanticCheck --> Cache[üíæ Validation Cache<br/>37% speedup]
    SemanticCheck --> Pass[‚úÖ VALIDATION PASSED]
    
    TypeCheck -.Fail.-> Fail[‚ùå VALIDATION FAILED]
    
    Cache -.Reuse.-> TypeCheck
    
    style TypeCheck fill:#00ff88,stroke:#00ff88,color:#000
    style InvariantCheck fill:#ffff00,stroke:#ffff00,color:#000
    style Cache fill:#ff00ff,stroke:#ff00ff,color:#000
```

**Description**: Shows the 3-layer contract validation system (type checking, mathematical invariants, semantic validation) with performance caching. Illustrates the 37% speedup from contract validation caching and the <5ms p95 latency target.

**References**: 
- [DATA_CONTRACTS.md](DATA_CONTRACTS.md) - Contract validation details
- README.md - Performance y Optimizaciones section

---

### 7Ô∏è‚É£ Deployment & Monitoring Infrastructure

**Location**: `docs/diagrams/07_deployment_monitoring.png`

```mermaid
graph TB
    Traffic[üåê Incoming Traffic] --> Router[üîÄ Traffic Router<br/>5%‚Üí25%‚Üí100%]
    
    Router --> Baseline[üì¶ Baseline v1.0<br/>Current Production]
    Router --> Canary[üê§ Canary v2.0<br/>New Deployment]
    
    Baseline & Canary --> Tracing[üìä OpenTelemetry<br/>28 Flows + 11 Components]
    Baseline & Canary --> Metrics[üìà Metrics Collector<br/>Error/Latency/Availability]
    
    Metrics --> SLO[üéØ SLO Monitor<br/>99.5% Avail, 200ms p95, 0.1% Error]
    Tracing -.Correlate.-> SLO
    
    SLO --> Decision[üß† Decision Engine<br/>Rollback or Promote]
    Decision --> Promote[‚úÖ PROMOTE<br/>Canary‚Üí100%]
    Decision --> Rollback[‚ö†Ô∏è ROLLBACK<br/>to Baseline]
    
    style Router fill:#00ff88,stroke:#00ff88,color:#000
    style Tracing fill:#ff00ff,stroke:#ff00ff,color:#000
    style SLO fill:#ffff00,stroke:#ffff00,color:#000
    style Promote fill:#00ff88,stroke:#00ff88,color:#000
    style Rollback fill:#ff0000,stroke:#ff0000,color:#fff
```

**Description**: Illustrates canary deployment with progressive traffic routing (5%‚Üí25%‚Üí100%), OpenTelemetry distributed tracing for 28 critical flows, and SLO monitoring with automated rollback triggers. Shows integration between tracing, metrics collection, and decision engine.

**References**: 
- [DEPLOYMENT_INFRASTRUCTURE.md](DEPLOYMENT_INFRASTRUCTURE.md) - Complete deployment documentation
- README.md - Deployment Infrastructure section

---

### üé® Diagram Design Principles

All diagrams follow these **HYPER MODERN, FUTURISTIC NEO-PUNK** design principles:

**Color Scheme**:
- üü£ **Magenta (#ff00ff)**: CLI/Entry points/Critical gates
- üü¢ **Cyan (#00ffff)**: Core processing/Evidence registry
- üü° **Yellow (#ffff00)**: Evaluation/SLO monitoring
- üü¢ **Green (#00ff88)**: Success states/Validation passed
- üî¥ **Red (#ff0000)**: Failure states/Rollback actions
- üîµ **Blue (#00d4ff)**: Orchestration/Components

**Typography**: JetBrains Mono (monospace, technical aesthetic)

**Cardinality Annotations**: All edges labeled with relationship cardinality (1:1, 1:N, N:1)

**Graph Types**:
- **TB (Top-Bottom)**: Sequential flows, pipelines, CI/CD
- **LR (Left-Right)**: Data validation, contract checking

**Background**: Dark theme (#0a0e27) for high contrast and modern feel

---

### üì• Generating High-Resolution Images

To regenerate PNG images from DOT source files:

```bash
cd docs/diagrams
python3 generate_images.py
```

Requirements:
- Graphviz installed: `brew install graphviz` (macOS) or `apt-get install graphviz` (Linux)
- Python 3.7+

Output: 300 DPI PNG files suitable for documentation and presentations.

---

## üìö Documentaci√≥n Adicional

- **Visual Architecture Diagrams:** 7 advanced diagrams (see [Visual Architecture section](#-visual-architecture-diagrams))
- **P-D-Q Canonical Notation:** `docs/PDQ_CANONICAL_NOTATION.md` - Complete specification for question identifiers
- **Flujos Cr√≠ticos Detallados:** `FLUJOS_CRITICOS_GARANTIZADOS.md`
- **Arquitectura Completa:** `ARCHITECTURE.md`
- **Deprecations y Migraci√≥n:** `DEPRECATIONS.md`
- **Deployment:** `DEPLOYMENT_INFRASTRUCTURE.md`
- **Data Contracts:** `DATA_CONTRACTS.md`
- **Component Diagram:** `COMPONENT_DIAGRAM.md`

---

## ü§ù Contribuci√≥n

### Reglas para PRs

1. **Nunca** modificar el orden can√≥nico de flujos sin actualizar `tools/flow_doc.json`
2. **Siempre** ejecutar verificaci√≥n antes de commit: `python test_validation_end_to_end.py`
3. **Siempre** verificar que r√∫brica pase: `python miniminimoon_cli.py rubric-check`
4. **Nunca** importar m√≥dulos deprecados
5. **Siempre** mantener determinismo (seeds fijos, sin randomness)

### CI/CD Pipeline

```yaml
on: [pull_request]
jobs:
  validate:
    - freeze_configuration
    - verify_pre_execution
    - run_evaluation_triple
    - verify_post_execution
    - rubric_check
    - trace_matrix_generation
    - performance_gate (p95 latency < budget + 10%)
```

---

## üìû Soporte

**Documentaci√≥n:** Ver carpeta `docs/`  
**Verificaci√≥n:** `python miniminimoon_cli.py diagnostic` o `python test_validation_end_to_end.py`  
**CLI Help:** `python miniminimoon_cli.py --help`  
**Issues:** Reportar con logs de `artifacts/` adjuntos

---

## üìÑ Licencia

Ver archivo `LICENSE`

---

## üéØ Estado del Sistema

**√öltima verificaci√≥n:** 6 de octubre de 2025  
**Estado:** ‚úÖ OPERATIVO  
**Flujos cr√≠ticos:** 72/72 verificados  
**Gates de aceptaci√≥n:** 6/6 activos  
**Cobertura:** 300/300 preguntas

---

## ‚ö° Quick Reference (Comandos Comunes)

### Comandos de Instalaci√≥n
```bash
# Crear entorno virtual con Python 3.10
python3.10 -m venv venv
source venv/bin/activate  # Linux/macOS
# .\venv\Scripts\Activate.ps1  # Windows PowerShell

# Instalar dependencias
pip install -r requirements.txt

# Descargar modelos NLP
python -m spacy download es_core_news_sm
python -c "import nltk; nltk.download('punkt'); nltk.download('stopwords')"
```

### Comandos de Operaci√≥n
```bash
# 1. Congelar configuraci√≥n (obligatorio antes de cualquier evaluaci√≥n)
python miniminimoon_cli.py freeze

# 2. Evaluar un plan
python miniminimoon_cli.py evaluate --plan mi_plan.pdf --strict

# 3. Verificar resultados
python miniminimoon_cli.py verify

# 4. Validar r√∫brica
python miniminimoon_cli.py rubric-check output/answers_report.json config/RUBRIC_SCORING.json

# 5. Generar matriz de trazabilidad
python miniminimoon_cli.py trace-matrix
```

### Comandos de Verificaci√≥n
```bash
# Verificar que todos los m√≥dulos funcionan
python test_validation_end_to_end.py

# Diagn√≥stico completo del sistema
python miniminimoon_cli.py diagnostic

# Verificar reproducibilidad (triple-run)
for i in {1..3}; do python miniminimoon_cli.py evaluate --plan test.pdf > run_$i.json; done

# Ver versi√≥n y estado
python miniminimoon_cli.py version
```

### Comandos de Desarrollo
```bash
# Ejecutar tests unitarios
python -m pytest test_plan_sanitizer.py -v
python -m pytest test_document_segmenter.py -v
python -m pytest test_teoria_cambio.py -v

# Verificar todos los tests
python -m pytest -v

# Ver cobertura de tests
python -m pytest --cov=. --cov-report=html
```
